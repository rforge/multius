library("mice") 
library("norm") 
library("mitools")
library("DMwR")
library("psych")
library("lattice")
library("foreign")
library("VIM")
library("blockmodeling")
library("psych")
library("MASS")
library("arm")
library("rgl")
library("ggplot2")
library("reshape2")
library("combinat")
library("pdist")

source("myKnnImp.R")
###########################################################################################
#####                       PRIPRAVA IN PREGLED PODATKOV
###########################################################################################
# uvozimo podatke
podatki <- read.spss("Ess2e03_SlovenijaNA.sav", 
                     use.value.labels = FALSE, 
                     to.data.frame = TRUE, 
                     use.missings = TRUE)
data <- podatki[, c("gndr", "yrbrn", "F5", "F6","F7", "G91","G92", "G90a")]

# izracunamo starost
data$age <- 2003 - data$yrbrn

# izbrisemo nezaposlene
data <- data[data$G90a == 1&!is.na(data$G90a), c("gndr", "age", "F5", "F6","F7", "G91","G92")]

# manjse vrednosti (7 in 8) so tretirane kot manjkajoce
data$G92[data$G92<39]<-NA
table(data$G92)

# shranimo sezname srepemenljivk - vse spremenljivke
sprem <- c("gndr", "age", "F5", "F6","F7", "G91","G92")

# shranimo sezname srepemenljivk - numericne spremenljvike
numSprem <- c("age","F7", "G91","G92")

# shranimo sezname srepemenljivk - opisne spremenljivke
opisSprem <- c("gndr", "F5", "F6")  

# dolga imena spremenljivk
attributes(podatki)$variable.labels[sprem] 

# pogledamo, koliko je manjkajocih vrednosti
round(colMeans(is.na(data))*100)

# pogledamo manjkajoce vrednosti po enotah
matrixplot(data)
matrixplot(data, sortby = "G91")
matrixplot(data, sortby = "F5")

# pogledamo, ali obstajajo korelacije med manjkajocimi vrednostmi
is.miss <- matrix(as.numeric(is.na(data)), ncol = ncol(data))
manjkajoce <- cor(is.miss)
rownames(manjkajoce) <- colnames(manjkajoce) <- colnames(data)
manjkajoce[is.na(manjkajoce)] <- 0
plot.mat(manjkajoce)

# testiramo MAR mehanizmem manjkajocih vrednosti
t.test(data$G92~is.na(data$G91))
prop.table(table(is.na(data$G91), data$gndr), 2)
chisq.test(table(is.na(data$G91), data$gndr))

# izracunamo osnovne statistike
summary(data[numSprem])

###########################################################################################
#####                       NALOGA 1
###########################################################################################
# izbor statistik in osnovne izracunane statistike
izbor <- c("n","mean","sd","se")

f <- formula(G91 ~ gndr + F5 + F7)

# analiza na podlagi razpolozljivih vrednosti
razpolozljive <- psych::describe(data[numSprem])
opisRazp <- as.data.frame(razpolozljive)[izbor]
(model_razpol <- lm(f, data = data))

# analiza na podlagi popolnih enot
comp <- complete.cases(data)
popolne <- psych::describe(data[comp, numSprem])
opisPop <- as.data.frame(popolne)[izbor]
(model_popolne <- lm(f, data = data))
# ko govorimo o analizi na podlagi popolnih enot, mislimo popolnih enot pri spremenljivkah, vkljucenih v analizo
# v primeru linearne regresije, mora imeti enota, vkljucena v analizo, vrednosti pri vseh spremenljivkah
# to pa ni potrebno npr. pri fakroski analizi, ki jo izvedemo na podlagi korelacijske matrike

# imputacije srednjih vrednosti
dataMEANimp <- data
for (i in numSprem){
  dataMEANimp[is.na(dataMEANimp[,i]), i] <- mean(dataMEANimp[,i], na.rm = TRUE)
}
opisMean <- data.frame(psych::describe(dataMEANimp[numSprem]))[izbor]
(model_srednje <- lm(f, data = dataMEANimp))

# KNN-imputacije (k-nearest-neighbour)
dataKNNimp <- knnImputation(data = data)
opisKnn <- data.frame(psych::describe(dataKNNimp[numSprem]))[izbor]
(model_knn <- lm(f, data = dataKNNimp))

# multiple imputacije
md.pattern(data) #vzorec manjkajocih podatkov
miceImp <-  mice(data, m=5, maxit=50)
# diagnostika
miceImp$nmis  # stevilo manjkajocih podatkov po spremenljivkah
plot(miceImp,layout=c(2,6)) #konvergenca za numericne spremenljivke (povprecje in sd)
## primerjava porazdelitev imputiranih in merjenih podazdelitev za numericne spremenljivke
bwplot(miceImp) 
densityplot(miceImp)
stripplot(miceImp)
xyplot(miceImp, G91 ~ age | .imp, pch = 20, cex = 1.4)
xyplot(miceImp, G91 ~ G92 | .imp, pch = 20, cex = 1.4)
### ocenjavanje povprecja in njene  SE na podlagi MI
m <- miceImp$m
miMeans <- numeric(m) #vektor za ocene povprecij iz imutacij
miVars <- numeric(m)  #vektor za ocene varianc ocen povprecij iz imputacij
Vars <- numeric(m) # vektor za ocene varianc
n <- dim(data)[1]
for(i in 1:m){
  miMeans[i] <- mean(complete(miceImp,i)$G91) # izracunamo ocnene za vsako imputacijo
  miVars[i] <- var(complete(miceImp,i)$G91)/n  # in variance ocen (kvadrati se)
  Vars[i] <- var(complete(miceImp,i)$G91)
}
# izracunamo povprecje povprecij
mean(miMeans)
# izracunamo variance
mean(Vars)
# izracunamo varianco povprecij (standardno napako)
sqrt(mean(miVars)+(m+1)/m*var(miMeans))

# zdruzimo rezultate s funkcijo MIcombine
summary(MIcombine(results=as.list(miMeans), variances=as.list(miVars))) 

# shranimo rezultate za G91
opisMice <- c(n, mean(miMeans), sqrt(mean(Vars)), sqrt(mean(miVars)+(m+1)/m*var(miMeans)))

# popravimo oceno stopinj prostosti (za izracun IZ uporabimo t porazdelitev in ne normalne, kot zgoraj)
summary(MIcombine(results=as.list(miMeans), variances=as.list(miVars), df.complete=n-1)) 

# vec rezultatov
MIcombine(results=as.list(miMeans), variances=as.list(miVars), df.complete=n-1)[]

## enako s funkcijami iz paketka mice - funkcija lahko zdruzi rezultate statisticnih modelov (R-jevih funkcij)
# en od njih je lm
# povprecje je konstanta pri lm, ce nimamo neodvisnih spremenljivk
lmG91mean <- with(data=miceImp, exp=lm(G91~1)) # izracunana ocene za vsa imputirana podatkovja
summary(pool(lmG91mean))  # zdruzimo rezultate

lmF <- with(data=miceImp, exp=lm(G91 ~ gndr + F5 + F7)) # izracunana ocene za vsa imputirana podatkovja
lmFpool <- summary(pool(lmF))  # zdruzimo rezultate

# primerjamo ocene regresijskih koeficientov glede na razlicne metode imputacij
coefplot(model_razpol)
coefplot(model_popolne, add = TRUE, col = "red",  offset=0.1)
coefplot(model_srednje, add = TRUE, col = "blue",  offset=0.2)
coefplot(model_knn, add = TRUE, col = "green", offset=0.3)
coefplot.default(coefs=lmFpool[-1,"est"],sds=lmFpool[-1,"se"], add = TRUE, col = "magenta", offset=0.4)
legend("bottomright", c("razpolozljive","popolne", "srednje", "knn", "mice"), lty = 1, col = c("black", "red", "blue", "green", "magenta"))

# EM-algoritem
dataPrep <- prelim.norm(as.matrix(data[numSprem]))   #do preliminary manipulations
thetahat <- em.norm(dataPrep)   #compute mle
resEM <- getparam.norm(dataPrep, thetahat, corr=TRUE) #get parameters
resEM$mu #means
resEM$sdv #standard deviations
opisEM <- data.frame(n=nrow(data[numSprem]), mean=resEM$mu, sd=resEM$sdv, se=resEM$sdv/sqrt(sum(!is.na(data$G91))))
# zgornji nacin ocene velikosti vzorca je konzervativen - ocene so visje
# ce bi kot n vzeli velikost celotnega vzorca, bi bila ocena prenizka
rownames(opisEM) <- numSprem

# korelacije na osnovi razpolozljivih enot
corRazp <- cor(data[numSprem],use = "p")[3,]
# korelacije na osnovi popolnih enot
corPop <- cor(data[numSprem],use = "c")[3,]
# korelacije dobljene z EM algoritmom
corEM <- resEM$r[3,]
# korelacije na osnovi imputacij srednjih vrednosti
corMean <- cor(dataMEANimp)[6, c(2, 5, 6, 7)]
# korelacije na osnovi KMM algoritma
corKnn <- cor(dataKNNimp[numSprem])[3,]
# MICE korelcija
corMice <- c(
  summary(pool(with(data=miceImp,exp=lm(scale(age)~scale(G91)))))[2,1],
  summary(pool(with(data=miceImp,exp=lm(scale(F7)~scale(G91)))))[2,1],
  1, # za konsistentnost
  summary(pool(with(data=miceImp,exp=lm(scale(G92)~scale(G91)))))[2,1]  
) 


zdruzeno <- rbind(opisRazp["G91",],
                  opisPop["G91",],
                  opisMean["G91",],
                  opisKnn["G91",],
                  opisMice, 
                  opisEM["G91",])
rownames(zdruzeno) <- c("razpolozljive", "popolne", "mean", "knn", "mice", "em")
round(zdruzeno, 2)

zdruzenoCor <- rbind(corRazp, corPop, corMean, corKnn, corMice, corEM)
round(zdruzenoCor, 2)

###########################################################################################
#####                       NALOGA 2
###########################################################################################
# uvozimo podatke
podatki <- read.spss("Ess2e03_SlovenijaNA.sav", 
                     use.value.labels = TRUE, 
                     to.data.frame = TRUE, 
                     use.missings = TRUE)
podatki <- podatki[, c("gndr", "yrbrn", "F5", "F6","F7", "G91","G92", "G90a")]
podatki$age <- 2003 - as.numeric(as.character(podatki$yrbrn))
podatki$G92 <- as.numeric(as.character(podatki$G92))
podatki$G91 <- as.numeric(as.character(podatki$G91))
podatki$F7 <- as.numeric(as.character(podatki$F7))
# upostevamo samo popolne podatke
podatki[which(podatki$G92 < 39),] <- NA # odstranimo se tiste enote, ki imajo pri bruto placi vrednost manjso od 39 - manjkajoci podatek
podatki <- na.omit(podatki[, c("gndr", "age", "F5", "F6","F7", "G91","G92")])

# shranimo kopijo originalnih podatkov, originalnim bomo dodajali NA
podatkiORG <- podatki

# definiramo nuemricne spremenljvike - ne bomo uporabili istih spremenljivk za imputacije in za model !
numSprem <- c("age", "F7", "G91", "G92")

# izbor statistik in osnovne izracunane statistike
izbor <- c("n","mean","sd","se")

# regresijska formula
f <- formula(G91 ~ gndr + F5 + F7)

# analiza na originalnih podatkih
opisOrg <- as.data.frame(describe(podatkiORG[numSprem]))[izbor]
(model_org <- lm(f, data = podatkiORG))

# nastavimo delez manjkajocih vrednosti
pmis <- 0.5
nMiss <- round(nrow(podatki)*pmis)

# izberemo metodo, po kateri bomo vstavljali manjkajoce vrednosti
metoda.na <- "NMAR"
podatki<-podatkiORG

# sedaj generiramo majkajoce vrednosti po MCAR
if (metoda.na == "MCAR"){
  # slucajno izberemo vrstice, kjer bodo manjkajoce vrednosti
  set.na <- sample(nrow(podatki), size = nMiss)
  podatki$G91[set.na] <- NA
}

# sedaj generiramo majkajoce vrednosti po NMAR
if (metoda.na == "NMAR"){
  # izracunamo verjetnost za NA, ki je odvisna od vrednosti spremenljivke, za katermo generiramo NA
  verjetnosti.na <- podatki$G91/(sum(podatki$G91))
  # s temi verjetnostmi izberemo enote, ki bodo imele NA
  set.na <- sample(length(verjetnosti.na), size = nMiss, prob = verjetnosti.na)
  podatki$G91[set.na] <- NA
}

# sedaj generiramo majkajoce vrednosti po MAR
if (metoda.na == "MAR"){
  # izracunamo verjetnost za NA, ki je odvisna od vrednosti DRUGE spremenljivke, za katermo generiramo NA
  verjetnosti.na <- podatki$age/(sum(podatki$age))
  # s temi verjetnostmi izberemo enote, ki bodo imele NA
  set.na <- sample(length(verjetnosti.na), size = nMiss, prob = verjetnosti.na)
  podatki$G91[set.na] <- NA  
}

# dodamo nekaj manjkajocih vrednosti se k eni drugi spremenljivki, zato da bodo rezultati pri 
# complete cases in pairwise razlicni
podatki[sample(nrow(podatki), size = nMiss), "F7"] <- NA

# pogledamo, ali smo pravilno generirali podatke
matrixplot(podatki)
matrixplot(podatki, sortby = "G92")
tmp <- cbind(podatki, podatkiORG$G91)
colnames(tmp)[ncol(podatki)+1] <- "G91_org"
matrixplot(tmp, sortby = "G91_org")

# analiza na podlagi razpolozljivih vrednosti
razpolozljive <- psych::describe(podatki[numSprem])
opisRazp <- as.data.frame(razpolozljive)[izbor]
# povej, zakaj tukaj ne bomo delali linearne regresije

# analiza na podlagi popolnih enot
comp <- complete.cases(podatki)
popolne <- psych::describe(podatki[comp, numSprem])
opisPop <- as.data.frame(popolne)[izbor]
(model_popolne <- lm(f, data = podatki[comp, ]))

# imputacije srednjih vrednosti
dataMEANimp <- podatki
for (i in numSprem){
  dataMEANimp[is.na(dataMEANimp[,i]), i] <- mean(dataMEANimp[,i], na.rm = T)
}
opisMean <- as.data.frame(psych::describe(dataMEANimp[numSprem]))[izbor]
(model_srednje <- lm(f, data = dataMEANimp))

# KNN-imputacije (k-nearest-neighbour)
dataKNNimp <- knnImputation(data = podatki)
opisKnn <- as.data.frame(psych::describe(dataKNNimp[numSprem]))[izbor]
(model_knn <- lm(f, data = dataKNNimp))

# multiple imputacije
miceImp <-  mice(podatki, m=5, maxit=30)
# diagnostika
plot(miceImp,layout=c(2,6)) #konvergenca za numericne spremenljivke (povprecje in sd)
## primerjava porazdelitev imputiranih in merjenih podazdelitev za numericne spremenljivke
densityplot(miceImp)
### ocenjavanje povprecja in njene  SE na podlagi MI
m <- miceImp$m
miMeans <- numeric(m) #vektor za ocene povprecij iz imutacij
miVars <- numeric(m)  #vektor za ocene varianc ocen povprecij iz imputacij
Vars <- numeric(m) # vektor za ocene varianc
n <- dim(podatki)[1]
for(i in 1:m){
  miMeans[i] <- mean(complete(miceImp,i)$G91) # izracunamo ocnene za vsako imputacijo
  miVars[i] <- var(complete(miceImp,i)$G91)/n  # in variance ocen (kvadrati se)
  Vars[i] <- var(complete(miceImp,i)$G91)
}
# shranimo rezultate za G91
opisMice <- c(n, mean(miMeans), sqrt(mean(Vars)), sqrt(mean(miVars)+(m+1)/m*var(miMeans)))
# naredimo linearno regresijo
lmF <- with(data=miceImp, exp=lm(G91 ~ gndr + F5 + F7)) # izracunana ocene za vsa imputirana podatkovja
lmFpool <- summary(pool(lmF))  # zdruzimo rezultate

# primerjamo ocene regresijskih koeficientov glede na razlicne metode imputacij
coefplot(model_org)
coefplot(model_popolne, add=TRUE, col = "red",  offset=0.1)
coefplot(model_srednje, add = TRUE, col = "blue",  offset=0.2)
coefplot(model_knn, add = TRUE, col = "green", offset=0.3)
coefplot.default(coefs=lmFpool[-1,"est"],sds=lmFpool[-1,"se"], add = TRUE, col = "magenta", offset=0.4)
legend("bottomright", c("originalni", "popolne", "srednje", "knn", "mice"), lty = 1, col = c("black", "red", "blue", "green", "magenta"))

# EM-algoritem
dataPrep <- prelim.norm(as.matrix(podatki[numSprem]))   #do preliminary manipulations
thetahat <- em.norm(dataPrep)   #compute mle
resEM <- getparam.norm(dataPrep, thetahat, corr=TRUE) #get parameters
resEM$mu #means
resEM$sdv #standard deviations
opisEM <- data.frame(n=nrow(podatki[numSprem]), mean=resEM$mu, sd=resEM$sdv, se=resEM$sdv/sqrt(sum(!is.na(podatki$G91))))
rownames(opisEM) <- numSprem

# korelacije na oroginalnih pdoatkih
corOrg <- cor(podatkiORG[numSprem])[3,]
# korelacije na osnovi razpolozljivih enot
corRazp <- cor(podatki[numSprem],use = "p")[3,]
# korelacije na osnovi popolnih enot
corPop <- cor(podatki[numSprem],use = "c")[3,]
# korelacije dobljene z EM algoritmom
corEM <- resEM$r[3,]
# korelacije na osnovi imputacij srednjih vrednosti
corMean <- cor(dataMEANimp[, numSprem])[3, ]
# korelacije na osnovi KMM algoritma
corKnn <- cor(dataKNNimp[numSprem])[3,]
# MICE korelcija
corMice <- c(
  summary(pool(with(data=miceImp,exp=lm(scale(age)~scale(G91)))))[2,1],
  summary(pool(with(data=miceImp,exp=lm(scale(F7)~scale(G91)))))[2,1],
  1, # za konsistentnost
  summary(pool(with(data=miceImp,exp=lm(scale(G92)~scale(G91)))))[2,1]  
) 

zdruzeno <- rbind(opisOrg["G91",],
                  opisRazp["G91",],
                  opisPop["G91",],
                  opisMean["G91",],
                  opisKnn["G91",],
                  opisMice,
                  opisEM["G91",])
rownames(zdruzeno) <- c("org","razpolozljive", "popolne", "mean", "knn", "mice", "em")
round(zdruzeno, 2)

zdruzenoCor <- rbind(corOrg, corRazp, corPop, corMean, corKnn, corMice, corEM)
round(zdruzenoCor, 2)
###########################################################################################
#####                       NALOGA 3
###########################################################################################
gen.na.data <- function(n = 1000, miss.na = 0.5){
  # generirano kovariate - originalne spremenljivke brez NA
  # definicijo mu in Sigma lahko damo tudi izven funkcije
  mu <- c(3, 3, 4, 1)
  Sigma <- rbind(c(0.5, 0.1, 0.2, 0.3),
                 c(0.1, 1.0, 0.4, 0.1),
                 c(0.2, 0.4, 1.0, 0.2),
                 c(0.3, 0.1, 0.2, 1.0))
  
  podatki <- mvrnorm(n = n, mu = mu, Sigma = Sigma)
  colnames(podatki) <- paste("x", 1:length(mu), sep="")
  
  # generiramo ciljno spremenljivko ("odvisno spremenljivko")
  y <- NULL
  b0 <- -4.5
  b1 <- 0.8
  b2 <- 0.6
  b3 <- 1.0
  b4 <- -0.5
  y <- b0 + podatki[, "x1"]*b1 + podatki[, "x2"]*b2 + podatki[, "x3"]*b3 + podatki[, "x4"]*b4 + rnorm(n, 0, 1)
  # summary(lm(y ~ x1 + x2 + x3 + x4))
  
  # zdruzimo podatke
  podatki <- data.frame(cbind(podatki, y))
  
  # nastavimo stevilo manjkajocih
  nMiss <- round(n*miss.na)
  
  # MCAR manjkajoce vrednosti manjkajo povsem slucajno
  podatki$MCARY <- y
  podatki$MCARY[sample(1:n, nMiss)] <- NA
  # pogledamo, da so manjkajoce vrednosti odivsne spremenljivke res neodvisne od kovariat
  # (summary(glm(is.na(MCARY) ~ x1 + x2 + x3 + x4, data = podatki, family = "binomial")))
  
  # MAR Y manjka z verjetnostjo sorazmerno z vrednostjo X
  podatki$MARY <- y
  koef <- NULL
  b0 <- 2.5
  b1 <- 0.5
  b2 <- 0.3
  b3 <- 0.25
  b4 <- 0.35
  koef <- (b0 + podatki[, "x1"]*b1 + podatki[, "x2"]*b2 + podatki[, "x3"]*b3 + podatki[, "x4"]*b4)
  verjetnosti.na <- 1/(1+exp(koef))
  set.na <- sample(length(verjetnosti.na), size = nMiss, prob = verjetnosti.na)
  podatki$MARY[set.na] <- NA
  # (summary(glm(is.na(MARY) ~ x1 + x2 + x3 + x4, data = podatki, family = "binomial")))
  
  # NMAR verjetnost, da vrednost Y manjka je sorazmerna z njeno vrednostjo
  podatki$NMARY <-podatki$y 
  # s temi verjetnostmi generiramo manjkajoce vrednosti
  # pazimo, da ni negativnih vrednosti
  tmp <- podatki$y
  tmp <- tmp - min(tmp); tmp <- tmp+0.05*mean(tmp)
  verjetnosti.na <- tmp/(sum(tmp))
  set.na <- sample(length(verjetnosti.na), size = nMiss, prob = verjetnosti.na)
  podatki$NMARY[set.na] <- NA
  
  return(podatki)
}

# generiramo eno podatkovje
n <- 1000; miss.na <- 0.15; m <- 1000
podatki <- gen.na.data(n = n, miss.na = miss.na)
head(podatki)

# delez manjkajocih
miss.na <- 0.3
nMiss <- n*miss.na

# izberemo mehanizem
mehanizem <- "MCARY"

# pripravimo podatkovni okvir za rezultate
rezultatiMISS <- matrix(NA, nrow = m, ncol = 12)
colnames(rezultatiMISS) <- c("mean_raz", "se_raz", "sd_raz", "mean_knn", "se_knn", "sd_knn", "mean_em", "se_em", "sd_em", "mean_mi", "se_mi", "sd_mi")
statistikeORG <- matrix(NA, nrow = m, ncol = 3)
colnames(statistikeORG) <- c("mean", "se", "sd")

xVars <- paste0("x", 1:4)

for (i in 1:m){
  # generiramo podatke
  podatki <- gen.na.data(n = n, miss.na = miss.na)
  
  # shranimo statistike za popolno podatkovje
  statistikeORG[i, ] <- c(mean(podatki$y), sd(podatki$y)/sqrt(n), sd(podatki$y))
  
  # dodamo dodatne manjkajoce vrednosti neodvisnim spremenljivkam
  podatki[sample(1:n, size = nMiss), 1] <- NA
  podatki[sample(1:n, size = nMiss), 2] <- NA
  
  if (mehanizem == "MCARY") podatki  <- podatki[, c(xVars,"MCARY")]
  if (mehanizem == "MARY") podatki  <- podatki[, c(xVars,"MARY")]
  if (mehanizem == "NMARY") podatki  <- podatki[, c(xVars,"NMARY")]
  
  # spremenimo ime zadnjega stolpca - iz prakticnih razlogov
  colnames(podatki)[5] <- "y" 
  
  # analiza na podlagi razpolozljivih vrednosti
  razpolozljive <- na.omit(podatki)
  rezultatiMISS[i, 1:3] <- c(mean(razpolozljive$y), sd(razpolozljive$y)/sqrt(length(razpolozljive$y)), sd(razpolozljive$y))
  
  # KNN-imputacije (k-nearest-neighbour)
  dataKNNimp <- knnImputation(data = podatki) 
  rezultatiMISS[i, 4:6] <- c(mean(dataKNNimp$y), sd(dataKNNimp$y)/sqrt(sum(!is.na(podatki$y))), sd(dataKNNimp$y))
  
  # EM-algoritem
  dataPrep <- prelim.norm(as.matrix(podatki))
  thetahat <- em.norm(dataPrep)  
  resEM <- getparam.norm(dataPrep, thetahat, corr=TRUE) 
  rezultatiMISS[i, 7:9] <- c(resEM$mu[5], resEM$sd[5]/sqrt(sum(!is.na(podatki$y))), resEM$sd[5]) 
  
  # multiple imputacije
  miceImp <-  mice(podatki, m=5, maxit=30)
  k <- miceImp$m
  miMeans <- numeric(k) 
  miVars <- numeric(k)  
  n <- dim(podatki)[1]
  for(j in 1:k){
    miMeans[j] <- mean(complete(miceImp,j)$y)
    miVars[j] <- var(complete(miceImp,j)$y)/n 
  }
  povp <- mean(miMeans)
  se <- sqrt(mean(miVars)+(k+1)/k*var(miMeans))
  sd <- sqrt(mean(miVars*n)) 
  rezultatiMISS[i, 10:12] <- c(povp, se, sd)
}

# rezultate najdete v spletni ucilnici
load(file = "predracunano/missMARY.rData", verbose = TRUE)
load(file = "predracunano/orgMARY.rData", verbose = TRUE)

# izracunamo pristranskost ocene povprecij
pristranskosti <- rezultatiMISS - matrix(rep(statistikeORG, 4), nrow = 200)
pristranskostMARY_mean <- round(colMeans(pristranskosti[, c(1, 4, 7, 10)]), 3)

# izracunamo variabilnost ocen povprecij (ocenjenih z razlicnimi metodami)
# dejanska variabilnost
apply(rezultatiMISS[,0:3*3+1], 2, sd)
# izracunamo pricakovano vrednost ocene variabilnosti ocen povprecij, ocenjenih z razlicnimi metodami
# ocenjena variabilnost
colMeans(rezultatiMISS[,0:3*3+2])
pristranskostMARY <- apply(rezultatiMISS[,0:3*3+1], 2, sd) - colMeans(rezultatiMISS[,0:3*3+2])

load(file = "predracunano/missMCARY.rData", verbose = TRUE)
load(file = "predracunano/orgMCARY.rData", verbose = TRUE)

pristranskosti <- rezultatiMISS - matrix(rep(statistikeORG, 4), nrow = 200)
pristranskostMCARY_mean <- round(colMeans(pristranskosti[, c(1, 4, 7, 10)]), 3)
pristranskostMCARY <- apply(rezultatiMISS[,0:3*3+1], 2 ,sd) - colMeans(rezultatiMISS[,0:3*3+2])

load(file = "predracunano/missNMARY.rData", verbose = TRUE)
load(file = "predracunano/orgNMARY.rData", verbose = TRUE)

pristranskosti <- rezultatiMISS - matrix(rep(statistikeORG, 4), nrow = 200)
pristranskostNMARY_mean <- round(colMeans(pristranskosti[, c(1, 4, 7, 10)]), 3)
pristranskostNMARY <- apply(rezultatiMISS[,0:3*3+1], 2 ,sd) - colMeans(rezultatiMISS[,0:3*3+2])

# skupni rezultati za pristranskost za povprecje
rez <- round(rbind(pristranskostNMARY_mean, pristranskostMCARY_mean, pristranskostMARY_mean), 3)
rownames(rez) <- c("NMAR", "MCAR", "MAR")
colnames(rez) <- c("razpolozljive", "KNN", "EM", "MI")
rez <- rez[c("NMAR", "MAR", "MCAR"),]

Mrez <- melt(data = rez)
ggplot(data = Mrez, aes(y = value, x = Var1, color = Var2, group = Var2)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = 0) +
  labs(x = "mehanizem generiranja manjkajocih vrednosti", y = "pristranskost", color = "metoda")

# skupni rezultati za pristranskost standardnih napak
rez <- round(rbind(pristranskostNMARY, pristranskostMCARY, pristranskostMARY), 3)
rownames(rez) <- c("NMAR", "MCAR", "MAR")
colnames(rez) <- c("razpolozljive", "KNN", "EM", "MI")
rez <- rez[c("NMAR", "MAR", "MCAR"),]

Mrez <- melt(data = rez)
ggplot(data = Mrez, aes(y = value, x = Var1, color = Var2, group = Var2)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = 0) +
  labs(x = "mehanizem generiranja manjkajocih vrednosti", y = "pristranskost standardnih napak", color = "metoda") 
# pozitivna vrednost pomeni, da so standardne napake podcenjene
###########################################################################################
#####                       NALOGA 4
###########################################################################################
set.seed(2019)
n <- 300
# Najprej generiramo eno skupino
mu <- c(5,5,5)
Sigma <- diag(3) 
prva_skupina <- mvrnorm(n = n, mu = mu, Sigma = Sigma)
# Sedaj podobno generiramo se eno skupino, ki bo od prve odmaknjena za 6
mu <- c(11, 11, 11)
Sigma <- diag(3) 
druga_skupina <- mvrnorm(n = n, mu = mu, Sigma = Sigma)
# Sedaj podobno generiramo se tretjo skupino:
mu <- c(11, 11, 8)
Sigma <- diag(3) 
tretja_skupina <- mvrnorm(n = n, mu = mu, Sigma = Sigma)

# Vse tri skupine zdruzimo v en podatkovni okvir
vse_skupine <- rbind(prva_skupina, druga_skupina, tretja_skupina)

# shranimo pripadnost k skupini
cluster <-  rep(1:3, each = n)
vse_skupine <- cbind(vse_skupine, cluster)

# shranimo kopijo originalnih podatkov
vse_skupineOrg <- vse_skupine

# pogledamo podatke
pairs(~ vse_skupine[,1] + vse_skupine[,2] + vse_skupine[,3], col = vse_skupine[,4])

# nastavimo delez manjkajocih vrednosti
pmis <- 0.75
# izracunamo stevilo manjkajocih vrednosti
nMiss <- round(3*n*pmis)

# sedaj generiramo majkajoce vrednosti po MAR
verjetnosti.na <- vse_skupine[,3]/sum(vse_skupine[,3])
set.na <- sample(length(verjetnosti.na), size = nMiss, prob = verjetnosti.na)
vse_skupine[set.na, 1] <- NA

tmp <- max(vse_skupine[,3]) - vse_skupine[,3] + 1
verjetnosti.na <- tmp/sum(tmp)
set.na <- sample(length(verjetnosti.na), size = nMiss, prob = verjetnosti.na)
vse_skupine[set.na, 2] <- NA

# pogledamo, kako smo generirali
matrixplot(vse_skupine, sortby = "V3")


# opravimo razvrscanje v skupine, npr. k-means

# ... na originalnih podatkih
fitOrg <- kmeans(vse_skupineOrg[,1:3], 3) 
# pogledamo velikosti dobljenih skupin
velikosti <- round(prop.table(table(fitOrg$cluster)),2)
# pogledamo centroide
centroidi <- unlist(by(vse_skupineOrg[, -4], fitOrg$cluster, colMeans))
# pogledamo ujemanje z originalno razvrstitvijo
randovAll <- crand2(vse_skupine[, 4], fitOrg$cluster)
randovPop <- NA # (samo za popolne enote)
# zdruzimo rezultate
rezOrg <- c(velikosti, centroidi, randovAll, randovPop)

# ... na podlagi popolnih enot
popolni <- complete.cases(vse_skupine[,1:3])
fit <- kmeans(vse_skupine[popolni, 1:3], 3) 
# pogledamo velikosti dobljenih skupin
velikosti <- round(prop.table(table(fit$cluster)),2)
# pogledamo centroide
centroidi <- unlist(by(vse_skupine[popolni, -4], fit$cluster, colMeans))
# pogledamo ujemanje z originalno razvrstitvijo
randovAll <- NA # (za vse enote)
randovPop <- crand2(vse_skupine[popolni, 4], fit$cluster)
# zdruzimo rezultate
rezPop <- c(velikosti, centroidi, randovAll, randovPop)

# ... na podlagi KNN algoritma
dataKNNimp <- knnImputation(data = as.matrix(vse_skupine[,1:3])) 
fit <- kmeans(dataKNNimp, 3) 
# pogledamo velikosti dobljenih skupin
velikosti <- round(prop.table(table(fit$cluster)),2)
# pogledamo centroide
centroidi <- unlist(by(dataKNNimp, fit$cluster, colMeans))
# pogledamo ujemanje z originalno razvrstitvijo
randovAll <- crand2(vse_skupine[, 4], fit$cluster)
randovPop <- crand2(vse_skupine[popolni, 4], fit$cluster[popolni]) 
# zdruzimo rezultate
rezKnn <- c(velikosti, centroidi, randovAll, randovPop)

# na podlagi MICE algoritma
miceImp <-  mice(vse_skupine[,1:3], m=5, maxit=15)
plot(miceImp) 
popolnjeni <- complete(miceImp, 5) # vzamemo zadnje popolnjeno podatkovje
fit <- kmeans(popolnjeni, 3) 
# pogledamo velikosti dobljenih skupin
velikosti <- round(prop.table(table(fit$cluster)),2)
# pogledamo centroide
centroidi <- unlist(by(popolnjeni, fit$cluster, colMeans))
# pogledamo ujemanje z originalno razvrstitvijo
randovAll <- crand2(vse_skupine[, 4], fit$cluster)
randovPop <- crand2(vse_skupine[popolni, 4], fit$cluster[popolni])
# zdruzimo rezultate
rezMiceA <- c(velikosti, centroidi, randovAll, randovPop)

# vzeli bomo povprecja popolnjenih podatkov
popolnjeni <- (complete(miceImp, 1) + complete(miceImp, 2) + complete(miceImp, 3) + complete(miceImp, 4) + complete(miceImp, 5))/5
fit <- kmeans(popolnjeni, 3) 
# pogledamo velikosti dobljenih skupin
velikosti <- round(prop.table(table(fit$cluster)),2)
# pogledamo centroide
centroidi <- unlist(by(popolnjeni, fit$cluster, colMeans))
# pogledamo ujemanje z originalno razvrstitvijo
randovAll <- crand2(vse_skupine[, 4], fit$cluster)
randovPop <- crand2(vse_skupine[popolni, 4], fit$cluster[popolni])
# zdruzimo rezultate
rezMiceB <- c(velikosti, centroidi, randovAll, randovPop)

zdruzeni <- rbind(rezOrg, rezPop, rezKnn, rezMiceA, rezMiceB)
# S - share; C - centroid
colnames(zdruzeni) <- c("S1", "S2", "S3", names(centroidi), "randovAll", "randovPop")
rownames(zdruzeni) <- c("originalni", "popolni", "KNN", "MICE_A", "MICE_B")

# VELIKOSTI DOBLJENIH SKUPIN
VelMelt <- melt(zdruzeni[, 1:3])
ggplot(data = VelMelt, aes(y = value, x = Var1, fill = Var2)) +
  geom_bar(stat = "identity") +
  labs(y = "velikost skupin", x = "metoda", fill = "skupina")

# RANDOV INDEKS
RiMelt <- melt(zdruzeni[, 13:14])
ggplot(data = RiMelt, aes(y = value, x = Var1, fill = Var2)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(y = "Randov indeks", x = "metoda", fill = "podatki")

plot.mat(zdruzeni[, 4:12])
